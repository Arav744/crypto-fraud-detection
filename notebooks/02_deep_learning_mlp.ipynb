{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f84975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and processing data...\n",
      "Training shape: (32594, 165)\n",
      "Class Weights: {0: 0.5537170426746398, 1: 5.154016445287793}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Training...\n",
      "Epoch 1/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6227 - loss: 0.6480 - val_accuracy: 0.8928 - val_loss: 0.3692\n",
      "Epoch 2/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7969 - loss: 0.3703 - val_accuracy: 0.9314 - val_loss: 0.2277\n",
      "Epoch 3/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8666 - loss: 0.2888 - val_accuracy: 0.9370 - val_loss: 0.1887\n",
      "Epoch 4/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8907 - loss: 0.2618 - val_accuracy: 0.9554 - val_loss: 0.1542\n",
      "Epoch 5/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9044 - loss: 0.2463 - val_accuracy: 0.9385 - val_loss: 0.1684\n",
      "Epoch 6/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9138 - loss: 0.2241 - val_accuracy: 0.9587 - val_loss: 0.1303\n",
      "Epoch 7/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9187 - loss: 0.2180 - val_accuracy: 0.9606 - val_loss: 0.1234\n",
      "Epoch 8/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9256 - loss: 0.2186 - val_accuracy: 0.9505 - val_loss: 0.1501\n",
      "Epoch 9/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9313 - loss: 0.1875 - val_accuracy: 0.9581 - val_loss: 0.1340\n",
      "Epoch 10/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9331 - loss: 0.1791 - val_accuracy: 0.9689 - val_loss: 0.1089\n",
      "Epoch 11/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9379 - loss: 0.1898 - val_accuracy: 0.9646 - val_loss: 0.1143\n",
      "Epoch 12/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9390 - loss: 0.1838 - val_accuracy: 0.9667 - val_loss: 0.1143\n",
      "Epoch 13/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9416 - loss: 0.1706 - val_accuracy: 0.9725 - val_loss: 0.0991\n",
      "Epoch 14/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9470 - loss: 0.1595 - val_accuracy: 0.9590 - val_loss: 0.1247\n",
      "Epoch 15/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9404 - loss: 0.1653 - val_accuracy: 0.9650 - val_loss: 0.1110\n",
      "Epoch 16/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9447 - loss: 0.1561 - val_accuracy: 0.9682 - val_loss: 0.1052\n",
      "Epoch 17/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9458 - loss: 0.1630 - val_accuracy: 0.9719 - val_loss: 0.0979\n",
      "Epoch 18/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9477 - loss: 0.1543 - val_accuracy: 0.9673 - val_loss: 0.1043\n",
      "Epoch 19/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9483 - loss: 0.1477 - val_accuracy: 0.9689 - val_loss: 0.0993\n",
      "Epoch 20/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9509 - loss: 0.1473 - val_accuracy: 0.9722 - val_loss: 0.0925\n",
      "Epoch 21/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9554 - loss: 0.1358 - val_accuracy: 0.9710 - val_loss: 0.0978\n",
      "Epoch 22/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9536 - loss: 0.1391 - val_accuracy: 0.9676 - val_loss: 0.1040\n",
      "Epoch 23/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9522 - loss: 0.1388 - val_accuracy: 0.9681 - val_loss: 0.1048\n",
      "Epoch 24/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9538 - loss: 0.1364 - val_accuracy: 0.9722 - val_loss: 0.0946\n",
      "Epoch 25/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9563 - loss: 0.1284 - val_accuracy: 0.9716 - val_loss: 0.0961\n",
      "Epoch 26/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9535 - loss: 0.1350 - val_accuracy: 0.9747 - val_loss: 0.0910\n",
      "Epoch 27/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9556 - loss: 0.1300 - val_accuracy: 0.9787 - val_loss: 0.0833\n",
      "Epoch 28/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9585 - loss: 0.1280 - val_accuracy: 0.9750 - val_loss: 0.0864\n",
      "Epoch 29/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9574 - loss: 0.1247 - val_accuracy: 0.9775 - val_loss: 0.0826\n",
      "Epoch 30/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9604 - loss: 0.1178 - val_accuracy: 0.9705 - val_loss: 0.0967\n",
      "Epoch 31/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9533 - loss: 0.1274 - val_accuracy: 0.9728 - val_loss: 0.0940\n",
      "Epoch 32/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9585 - loss: 0.1232 - val_accuracy: 0.9761 - val_loss: 0.0832\n",
      "Epoch 33/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9600 - loss: 0.1214 - val_accuracy: 0.9689 - val_loss: 0.0983\n",
      "Epoch 34/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9526 - loss: 0.1262 - val_accuracy: 0.9678 - val_loss: 0.0987\n",
      "Epoch 35/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9573 - loss: 0.1288 - val_accuracy: 0.9755 - val_loss: 0.0849\n",
      "Epoch 36/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9586 - loss: 0.1165 - val_accuracy: 0.9768 - val_loss: 0.0820\n",
      "Epoch 37/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9608 - loss: 0.1175 - val_accuracy: 0.9755 - val_loss: 0.0830\n",
      "Epoch 38/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9619 - loss: 0.1113 - val_accuracy: 0.9705 - val_loss: 0.0948\n",
      "Epoch 39/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9588 - loss: 0.1177 - val_accuracy: 0.9741 - val_loss: 0.0841\n",
      "Epoch 40/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9600 - loss: 0.1147 - val_accuracy: 0.9718 - val_loss: 0.0937\n",
      "Epoch 41/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9604 - loss: 0.1118 - val_accuracy: 0.9736 - val_loss: 0.0873\n",
      "Epoch 42/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9624 - loss: 0.1049 - val_accuracy: 0.9725 - val_loss: 0.0876\n",
      "Epoch 43/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9628 - loss: 0.1067 - val_accuracy: 0.9773 - val_loss: 0.0804\n",
      "Epoch 44/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9627 - loss: 0.1128 - val_accuracy: 0.9710 - val_loss: 0.0949\n",
      "Epoch 45/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9641 - loss: 0.1069 - val_accuracy: 0.9693 - val_loss: 0.0951\n",
      "Epoch 46/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9600 - loss: 0.1077 - val_accuracy: 0.9794 - val_loss: 0.0743\n",
      "Epoch 47/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9623 - loss: 0.1030 - val_accuracy: 0.9728 - val_loss: 0.0888\n",
      "Epoch 48/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9607 - loss: 0.1078 - val_accuracy: 0.9771 - val_loss: 0.0776\n",
      "Epoch 49/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9656 - loss: 0.1000 - val_accuracy: 0.9718 - val_loss: 0.0916\n",
      "Epoch 50/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9607 - loss: 0.1044 - val_accuracy: 0.9773 - val_loss: 0.0775\n",
      "Epoch 51/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9665 - loss: 0.0978 - val_accuracy: 0.9753 - val_loss: 0.0826\n",
      "Epoch 52/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9629 - loss: 0.1008 - val_accuracy: 0.9782 - val_loss: 0.0736\n",
      "Epoch 53/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9674 - loss: 0.0994 - val_accuracy: 0.9782 - val_loss: 0.0778\n",
      "Epoch 54/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9660 - loss: 0.1001 - val_accuracy: 0.9761 - val_loss: 0.0809\n",
      "Epoch 55/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9659 - loss: 0.0961 - val_accuracy: 0.9779 - val_loss: 0.0781\n",
      "Epoch 56/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9641 - loss: 0.0984 - val_accuracy: 0.9799 - val_loss: 0.0688\n",
      "Epoch 57/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9704 - loss: 0.0886 - val_accuracy: 0.9753 - val_loss: 0.0802\n",
      "Epoch 58/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9633 - loss: 0.0983 - val_accuracy: 0.9776 - val_loss: 0.0772\n",
      "Epoch 59/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9664 - loss: 0.0981 - val_accuracy: 0.9750 - val_loss: 0.0818\n",
      "Epoch 60/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9651 - loss: 0.0942 - val_accuracy: 0.9735 - val_loss: 0.0858\n",
      "Epoch 61/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9676 - loss: 0.0864 - val_accuracy: 0.9735 - val_loss: 0.0855\n",
      "Epoch 62/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9644 - loss: 0.0965 - val_accuracy: 0.9790 - val_loss: 0.0739\n",
      "Epoch 63/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9700 - loss: 0.0834 - val_accuracy: 0.9799 - val_loss: 0.0693\n",
      "Epoch 64/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9673 - loss: 0.1005 - val_accuracy: 0.9748 - val_loss: 0.0797\n",
      "Epoch 65/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9661 - loss: 0.0984 - val_accuracy: 0.9767 - val_loss: 0.0804\n",
      "Epoch 66/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9694 - loss: 0.0898 - val_accuracy: 0.9798 - val_loss: 0.0703\n",
      "\n",
      "--- Deep Learning Evaluation ---\n",
      "\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Licit (0)       0.99      0.99      0.99     12587\n",
      "   Fraud (1)       0.89      0.87      0.88      1383\n",
      "\n",
      "    accuracy                           0.98     13970\n",
      "   macro avg       0.94      0.93      0.93     13970\n",
      "weighted avg       0.98      0.98      0.98     13970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "DATA_PATH_FEATURES = '../data/elliptic_txs_features.csv'\n",
    "DATA_PATH_CLASSES = '../data/elliptic_txs_classes.csv'\n",
    "\n",
    "print(\"Loading and processing data...\")\n",
    "df_classes = pd.read_csv(DATA_PATH_CLASSES)\n",
    "df_features = pd.read_csv(DATA_PATH_FEATURES, header=None)\n",
    "df_features.rename(columns={0: 'txId', 1: 'time_step'}, inplace=True)\n",
    "\n",
    "df_merged = pd.merge(df_features, df_classes, on='txId', how='left')\n",
    "df_clean = df_merged[df_merged['class'] != 'unknown'].copy()\n",
    "df_clean['class'] = df_clean['class'].map({'1': 1, '2': 0})\n",
    "\n",
    "X = df_clean.drop(columns=['txId', 'class', 'time_step'])\n",
    "y = df_clean['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training shape: {X_train_scaled.shape}\")\n",
    "\n",
    "counts = np.bincount(y_train)\n",
    "weight_for_0 = 1.0 / counts[0]\n",
    "weight_for_1 = 1.0 / counts[1]\n",
    "total = len(y_train)\n",
    "class_weight = {0: (weight_for_0 * total) / 2.0, \n",
    "                1: (weight_for_1 * total) / 2.0}\n",
    "\n",
    "print(f\"Class Weights: {class_weight}\")\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "opt = Adam(learning_rate=0.001) \n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "print(\"\\nStarting Training...\")\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=100, \n",
    "    batch_size=256,  \n",
    "    validation_split=0.2, \n",
    "    callbacks=[early_stop],\n",
    "    class_weight=class_weight, \n",
    "    verbose=1\n",
    ")\n",
    "print(\"\\n--- Deep Learning Evaluation ---\")\n",
    "y_pred_probs = model.predict(X_test_scaled)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int) \n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['Licit (0)', 'Fraud (1)']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
